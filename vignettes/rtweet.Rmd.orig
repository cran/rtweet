---
title: "Intro to rtweet"
output:
  rmarkdown::html_vignette:
    self_contained: false
vignette: >
  %\VignetteIndexEntry{Intro to rtweet}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, eval = TRUE, comment = "#>", collapse = TRUE,
  fig.path = "vignettes/files/", root.dir = "vignettes")
```

This vignette provides a quick tour of the R package.

```{r}
library("rtweet")
```

## Authenticate

First you should set up your own credentials, this should be done just once ever:

```{r, eval=FALSE}
auth_setup_default()
```

Which will look up your account on your browser and create a token and save it as default.
From now on, on this R session on others we can use this authentication with:

```{r, eval=FALSE}
auth_as("default")
```

Automatically rtweet will use that token in all the API queries it will do in the session.

If you want to set up a bot or collect a lot of information, please read the `vignette("auth", "rtweet")`.

```{r include=FALSE, purl=FALSE}
library("ggplot2")
library("dplyr")
library("rtweet")
auth_as(rtweet:::rtweet_test())
```

## Search tweets

You can search tweets:

```{r}
## search for 18000 tweets using the rstats hashtag
rstats <- search_tweets("#rstats", n = 100, include_rts = FALSE)
colnames(rstats)
rstats[1:5, c("created_at", "text", "id_str")]
```

The `include_rts = FALSE` excludes retweets from the search.

Twitter rate limits the number of calls to the endpoints you can do. 
See `rate_limit()` and the [rate limit section](#Rate-limit) below.
If your query requires more calls like the example below, simply set `retryonratelimit = TRUE` and rtweet will wait for rate limit resets for you.

```{r, eval=FALSE}
## search for 250,000 tweets containing the word data
tweets_peace <- search_tweets("peace", n = 250000, retryonratelimit = TRUE)
```

Search by geo-location, for example tweets in the English language sent from the United States.

```{r}
# search for tweets sent from the US 
# lookup_coords requires Google maps API key for maps outside usa, canada and world
geo_tweets <- search_tweets("lang:en", geocode = lookup_coords("usa"), n = 100)
geo_tweets[1:5, c("created_at", "text", "id_str", "lang", "place")]
```

You can check the location of these tweets with `lat_lng()`.
Or quickly visualize frequency of tweets over time using `ts_plot()` (if `ggplot2` is installed).

```{r plot1}
## plot time series of tweets
ts_plot(rstats) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold")) +
  labs(
    x = NULL, y = NULL,
    title = "Frequency of #rstats Twitter statuses from past 9 days",
    subtitle = "Twitter status (tweet) counts aggregated using three-hour intervals",
    caption = "Source: Data collected from Twitter's REST API via rtweet"
  )
```

## Posting statuses

You can post tweets with:

```{r}
post_tweet(paste0("My first tweet with #rtweet #rstats at ", Sys.time()))
```

It can include media and alt text:

```{r baseplot}
path_file <- tempfile(fileext = ".png")
png(filename = path_file)
plot(mpg ~ cyl, mtcars, col = gear, pch = gear)
dev.off()
post_tweet("my first tweet with #rtweet with media #rstats", media = path_file, media_alt_text = "Plot of mtcars dataset, showing cyl vs mpg colored by gear. The lower cyl the higher the mpg is.")
```

You can also reply to a previous tweet, retweet and provide additional information. 

## Get friends

Retrieve a list of all the accounts a **user follows**.
```{r}
## get user IDs of accounts followed by R Foundation
R_foundation_fds <- get_friends("_R_Foundation")
R_foundation_fds
```

Using `get_friends()` we can retrieve which users are being followed by the R Foundation. 

## Get followers

If you really want all the users that follow the account we can use `get_followers()`:
```{r}
R_foundation_flw <- get_followers("_R_Foundation", n = 30000, 
                                  retryonratelimit = TRUE)
```

Note that the `retryonratelimit` option is intended for when you need more queries than provided by Twitter on a given period. 
You might want to check with `rate_limit()` how many does it provide for the endpoints you are using. 
If exceeded `retryonratelimit` waits till the there are more calls available and then resumes the query.

## Lookup users

As seen above we can use `lookup_users()` to check their

```{r}
# Look who is following R Foundation
R_foundation_fds_data <- lookup_users(R_foundation_fds$to_id, verbose = FALSE)
R_foundation_fds_data[, c("name", "screen_name", "created_at")]

# Look 100 R Foundation followers
R_foundation_flw_data <- lookup_users(head(R_foundation_flw$from_id, 100), verbose = FALSE)
R_foundation_flw_data[1:5, c("name", "screen_name", "created_at")]
```

We have now the information from those followed by the R Foundation and its followers.
We can retrieve their latest tweets from these users:

```{r}
tweets_data(R_foundation_fds_data)[, c("created_at", "text")]
```

## Search users

Search for 1,000 users with the rstats hashtag in their profile bios.
```{r}
## search for users with #rstats in their profiles
useRs <- search_users("#rstats", n = 100, verbose = FALSE)
useRs[, c("name", "screen_name", "created_at")]
```

If we want to know what have they tweeted about we can use `tweets_data()`:
```{r}
useRs_twt <- tweets_data(useRs)
useRs_twt[1:5, c("id_str", "created_at", "text")]
```

## Get timelines

Get the most recent tweets from R Foundation.
```{r plot2}
## get user IDs of accounts followed by R Foundation
R_foundation_tline <- get_timeline("_R_Foundation")

## plot the frequency of tweets for each user over time
plot <- R_foundation_tline |> 
  filter(created_at > "2017-10-29") |> 
  ts_plot(by = "month", trim = 1L) +
  geom_point() +
  theme_minimal() +
  theme(
    legend.title = element_blank(),
    legend.position = "bottom",
    plot.title = element_text(face = "bold")) +
  labs(
    x = NULL, y = NULL,
    title = "Frequency of Twitter statuses posted by the R Foundation",
    subtitle = "Twitter status (tweet) counts aggregated by month from October/November 2017",
    caption = "Source: Data collected from Twitter's REST API via rtweet"
  )
```

## Get favorites

Get the 10 recently favorited statuses by R Foundation.

```{r}
R_foundation_favs <- get_favorites("_R_Foundation", n = 10)
R_foundation_favs[, c("text", "created_at", "id_str")]
```


## Get trends

Discover what's currently trending in San Francisco.
```{r}
world <- get_trends("world")
world
```

## Following users

You can follow users and unfollow them:

```{r}
post_follow("_R_Foundation")
post_unfollow_user("rtweet_test")
```

## Muting users

You can mute and unmute users:

```{r, eval=FALSE}
post_follow("rtweet_test", mute = TRUE)
post_follow("rtweet_test", mute = FALSE)
```


## Blocking users

You can block users and unblock them:

```{r}
user_block("RTweetTest1")
user_unblock("RTweetTest1")
```



## Rate limits

Twitter sets a limited number of calls to their endpoints for different authentications (check `vignette("auth", "rtweet")` to find which one is better for your use case).
To consult those limits you can use `rate_limt()`

```{r}
rate_limit()
# Search only those related to followers
rate_limit("followers")
```

The remaining column shows the number of times that you can call and endpoint (not the numbers of followers you can search). 
After a query the number should decrease until it is reset again. 

If your queries return an error, check if you already exhausted your quota and try after the time on "reset_at".

## Stream tweets

Randomly sample (approximately 1%) from the live stream of all tweets.
```{r, eval=FALSE}
## random sample for 30 seconds (default)
stream <- tempfile(fileext = ".json")
rt <- stream_tweets("rstats", file_name = stream)
```

Stream all geo enabled tweets from London for 15 seconds.
```{r, eval=FALSE}
## stream tweets from london for 60 seconds
stream2 <- tempfile(fileext = ".json")
stream_london <- stream_tweets(lookup_coords("london, uk"), timeout = 15, file_name = stream2)
```

Stream all tweets mentioning #rstats for a week.
```{r, eval=FALSE}
## stream london tweets for a week (60 secs x 60 mins * 24 hours *  7 days)
stream3 <- tempfile(fileext = ".json")
stream_tweets(
  "#rstats",
  timeout = 60 * 60 * 24 * 7,
  file_name = stream3,
  parse = FALSE
)

## read in the data as a tidy tbl data frame
rstats <- jsonlite::stream_in(stream3)
```

See the vignette on `vignette("stream", "rtweet")`.

## SessionInfo

To provide real examples the vignette is precomputed before submission.
Also note that results returned by the API will change.

```{r session, class.source = "fold-hide"}
sessionInfo()
```

